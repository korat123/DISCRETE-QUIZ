M|1|Which represents the upper bound complexity?|Big-O (O)|Big-Omega|Big-Theta|Little-o|Little-omega|A|Big-O describes the worst-case or upper bound.|O is for Upper.|Think of the ceiling.|BigO_Definitions
M|2|Order growth rates from smallest to largest:|n, n^2, log n, 2^n|log n, n, n^2, 2^n|n^2, n, log n, 2^n|2^n, n^2, n, log n|n, log n, n^2, 2^n|B|Correct order: Logarithmic < Linear < Polynomial < Exponential.|Log grows very slowly.|Exponential explodes.|BigO_Growth
M|3|What is O(3n^3 + 5n^2 + 100)?|O(n)|O(n^2)|O(n^3)|O(1)|O(3n^3)|C|We drop constants and keep only the highest degree term.|Look at the highest power.|Drop the coefficient 3.|BigO_Polynomials
M|4|Nested loops: 'for i=1 to n' inside 'for j=1 to n' is:|O(n)|O(log n)|O(n^2)|O(n log n)|O(1)|C|n iterations * n iterations = n^2.|Inner loop runs n times for each outer loop.|Multiply the complexities.|BigO_CodeAnalysis
M|5|Binary Search complexity is:|O(1)|O(log n)|O(n)|O(n^2)|O(n log n)|B|Binary search cuts the problem size in half each step.|Halving process implies Logarithm.|Base 2 logarithm.|BigO_Algorithms
M|6|f(n) = O(g(n)) means there exist constants C and k such that:|f(n) <= C*g(n) for n > k|f(n) >= C*g(n) for n > k|f(n) = C*g(n)|f(n) > g(n)|f(n) < g(n)|A|Definition of Big-O: f is bounded above by a multiple of g.|Less than or equal to.|Upper bound definition.|BigO_Definitions
M|7|What is the complexity of accessing an array element by index?|O(1)|O(n)|O(log n)|O(n^2)|O(n!)|A|Array access is direct and constant time.|It doesn't depend on array size.|Instant access.|BigO_DataStructures
M|8|Which function grows fastest?|n! (Factorial)|2^n (Exponential)|n^3 (Cubic)|n log n|100n|A|Factorial grows much faster than exponential.|Try n=10. 10! is huge.|n! > 2^n.|BigO_Growth
M|9|Loop 'for i = 1 to n; i = i * 2' is:|O(n)|O(n^2)|O(log n)|O(1)|O(n log n)|C|The variable i doubles each time, so it reaches n in log steps.|Doubling or halving implies Log.|Similar to binary search steps.|BigO_CodeAnalysis
M|10|Merge Sort average complexity:|O(n)|O(n^2)|O(n log n)|O(log n)|O(n!)|C|Divide and conquer sorting is typically n log n.|Better than bubble sort.|Log linear.|BigO_Algorithms
M|11|f(n) = n! is O(n^n)?|True|False|Maybe|Only for small n|Undefined|A|n! is approx (n/e)^n, which is <= n^n. So yes.|n terms of n is bigger than 1*2*...*n.|n^n is the upper bound of n!.|BigO_Growth
M|12|Bubble Sort worst case:|O(n)|O(n log n)|O(n^2)|O(log n)|O(1)|C|Nested loops comparing adjacent elements.|Verify pairs.|n*(n-1)/2 comparisons.|BigO_Algorithms
M|13|What is O(log(n^10))?|O(n^10)|O(10)|O(n)|O(log n)|O(n log n)|D|Log rule: log(n^k) = k * log n. Constants drop.|Pull the exponent out.|10 log n becomes log n.|BigO_MathRules
M|14|Algorithm A takes 2^n, B takes n^10. For very large n, which is faster?|A|B|Same|Depends on input|A is faster for even n|B|Polynomial (n^10) is always slower-growing than Exponential (2^n) eventually.|Exponential is worst.|n^10 wins in the long run.|BigO_Growth
M|15|Sum of 1 to n (1+2+...+n) is:|O(n)|O(n^2)|O(log n)|O(1)|O(n^3)|B|Sum formula is n(n+1)/2, which is n^2/2 + n/2.|Use Arithmetic Sum formula.|Highest term is n^2.|BigO_MathRules
M|16|Big-Omega (Omega) represents:|Upper Bound|Lower Bound|Tight Bound|Average Case|Equality|B|Omega is the opposite of Big-O.|Think 'Omega' starts from bottom.|At least this much work.|BigO_Definitions
M|17|Big-Theta (Theta) means:|f(n) is O(g(n)) AND f(n) is Omega(g(n))|f(n) is only O(g(n))|f(n) is only Omega(g(n))|f(n) != g(n)|None of above|A|Theta means tight bound (sandwiched between constants).|Both Upper and Lower bounds match.|Exact growth rate.|BigO_Definitions
M|18|2^n + n^100 is O(?)|O(n^100)|O(2^n)|O(n!)|O(n)|O(1)|B|Exponential dominates polynomial.|2^n grows faster.|Keep the dominant term.|BigO_Growth
M|19|Inner loop runs j=1 to i, Outer loop i=1 to n:|O(n)|O(n log n)|O(n^2)|O(log n)|O(1)|C|This runs 1+2+3+...+n times.|Sum of integers formula.|Equals n(n+1)/2.|BigO_CodeAnalysis
M|20|Is 1000000 member of O(1)?|Yes|No|Depends on n|Only on Tuesdays|Maybe|A|Any constant number is O(1).|It does not grow with n.|Constant time.|BigO_Definitions